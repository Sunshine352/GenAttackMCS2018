{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat modified implementation of gradient free black box adversarial attack approach from https://arxiv.org/abs/1805.11090 (for now the official repository is empty, but here's the link https://github.com/nesl/adversarial_genattack) for the competition (https://competitions.codalab.org/competitions/19090) organized as a part of Machines Can See 2018 summit (http://machinescansee.com/).\n",
    "\n",
    "You can find the baseline code for the competition here https://github.com/AlexanderParkin/MCS2018.Baseline. I used some of it for image preprocessing and saving adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from showprogress import showprogress\n",
    "\n",
    "import MCS2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the black box model before torch (doesn't work otherwise for some reason) :C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find details of the contest here https://competitions.codalab.org/competitions/19090.\n",
    "\n",
    "We first need to load the black box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget http://mcs2018-competition.visionlabs.ru/distribs/cuda9/ubuntu/MCS2018.cpython-36m-x86_64-linux-gnu.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "net = MCS2018.Predictor(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from genattack import *\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datalists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load the data used in the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python downloader.py --root /data --main_imgs --student_model_imgs --submit_list --pairs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also please unzip the data if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pairs = pd.read_csv('/data/mcs/pairs_list.csv')\n",
    "img_pairs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "REVERSE_MEAN = [-0.485, -0.456, -0.406]\n",
    "REVERSE_STD = [1/0.229, 1/0.224, 1/0.225]\n",
    "\n",
    "ATTACK_DIR = '/data/mcs/attack_imgs/'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize((112,112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs = 5\n",
    "dim = 512  # descriptor dim\n",
    "nchannels = 3\n",
    "h = 112\n",
    "w = 112\n",
    "N = 6  # size of population to evolve\n",
    "G = 500  # number of generations to evolve through\n",
    "p = torch.cuda.FloatTensor([0.005])\n",
    "alpha = torch.cuda.FloatTensor([1.])\n",
    "delta = torch.cuda.FloatTensor([0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following 2 functions are taken from original baseline repo to save adversarial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_normalize(tensor, mean, std):\n",
    "    '''reverese normalize to convert tensor -> PIL Image'''\n",
    "    tensor_copy = tensor.clone()\n",
    "    for t, m, s in zip(tensor_copy, mean, std):\n",
    "        t.div_(s).sub_(m)\n",
    "    return tensor_copy\n",
    "\n",
    "\n",
    "def tensor2img(tensor, on_cuda=True):\n",
    "    tensor = reverse_normalize(tensor, REVERSE_MEAN, REVERSE_STD)\n",
    "    # clipping\n",
    "    tensor[tensor > 1] = 1\n",
    "    tensor[tensor < 0] = 0\n",
    "    tensor = tensor.squeeze(0)\n",
    "    if on_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    return transforms.ToPILImage()(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ssim = []  # for images with low ssim\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in showprogress(img_pairs.index.values):\n",
    "    try:\n",
    "        pairs = {'source': img_pairs.loc[idx].source_imgs.split('|'),\n",
    "                 'target': img_pairs.loc[idx].target_imgs.split('|')}\n",
    "        source_img_names = pairs['source']\n",
    "        target_img_names = pairs['target']\n",
    "\n",
    "        targets = torch.cuda.FloatTensor(n_imgs, dim)\n",
    "        for source_img_name in source_img_names:\n",
    "            source_img_name = os.path.join('/data/mcs/imgs/', source_img_name)\n",
    "            source_img = Image.open(source_img_name)\n",
    "\n",
    "            x = transform(source_img)\n",
    "            x = x.cuda(async=True)\n",
    "            tavg = torch.cuda.FloatTensor(dim)\n",
    "            # since the task is to confuse black box between two identities,\n",
    "            # each having n_imgs images, we simply take average target descriptors\n",
    "            for i, target_img_name in enumerate(target_img_names):\n",
    "                target_img_name = os.path.join('/data/mcs/imgs/', target_img_name)\n",
    "                target_img = Image.open(target_img_name)\n",
    "\n",
    "                t = transform(target_img).unsqueeze(0).numpy()\n",
    "                targets[i] = torch.cuda.FloatTensor(net.submit(t))\n",
    "                tavg += targets[i]\n",
    "            tavg /= torch.norm(tavg)  # make avg descriptor of unit length\n",
    "\n",
    "            Pc = attack(x, tavg, delta, alpha, p, N, G, net)\n",
    "\n",
    "            ssimm = ssim(x.squeeze().permute(1,2,0).cpu().numpy(),\n",
    "                         Pc[0].permute(1,2,0).cpu().numpy(),\n",
    "                         multichannel=True)\n",
    "\n",
    "            d_adv = net.submit(Pc[0][None, :, :, :].cpu().numpy())\n",
    "            # compute L2 distances between target and adversarial descriptors\n",
    "            for i in range(n_imgs):\n",
    "                scores.append(np.linalg.norm(targets[i].cpu().numpy() - d_adv))\n",
    "            print(sum(scores[-5:]) / 5)  # print the mean score for the current source example\n",
    "\n",
    "            if ssimm < 0.95:\n",
    "                print('SSIM low: %s' % source_img_name)\n",
    "                low_ssim.append(source_img_name)\n",
    "                continue  # do not save images with low ssim, better retry for them after\n",
    "\n",
    "            # save adversarial example\n",
    "            attack_img = tensor2img(Pc[0], True)\n",
    "            attack_img.save(ATTACK_DIR + os.path.basename(source_img_name).replace('.jpg', '.png'))\n",
    "    except Exception as e:\n",
    "        print(source_img_name)\n",
    "        print(e)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(scores).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
